{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron\n",
    "\n",
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "#nn Layers\n",
    "w1 = torch.Tensor(2,2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2,1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)\n",
    "\n",
    "def sigmoid(x):\n",
    "    # sigmoid function\n",
    "    return 1.0 /  (1.0 + torch.exp(-x))\n",
    "    # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))\n",
    "    \n",
    "def sigmoid_prime(x):\n",
    "    #derivative of the sigmoid function\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "100 0.6931471824645996\n",
      "200 0.6931471824645996\n",
      "300 0.6931471824645996\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471824645996\n",
      "700 0.6931471824645996\n",
      "800 0.6931471824645996\n",
      "900 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "1100 0.6931471824645996\n",
      "1200 0.6931471824645996\n",
      "1300 0.6931471824645996\n",
      "1400 0.6931471824645996\n",
      "1500 0.6931471824645996\n",
      "1600 0.6931471824645996\n",
      "1700 0.6931471824645996\n",
      "1800 0.6931471824645996\n",
      "1900 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "2100 0.6931471824645996\n",
      "2200 0.6931471824645996\n",
      "2300 0.6931471824645996\n",
      "2400 0.6931471824645996\n",
      "2500 0.6931471824645996\n",
      "2600 0.6931471824645996\n",
      "2700 0.6931471824645996\n",
      "2800 0.6931471824645996\n",
      "2900 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "3100 0.6931471824645996\n",
      "3200 0.6931471824645996\n",
      "3300 0.6931471824645996\n",
      "3400 0.6931471824645996\n",
      "3500 0.6931471824645996\n",
      "3600 0.6931471824645996\n",
      "3700 0.6931471824645996\n",
      "3800 0.6931471824645996\n",
      "3900 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "4100 0.6931471824645996\n",
      "4200 0.6931471824645996\n",
      "4300 0.6931471824645996\n",
      "4400 0.6931471824645996\n",
      "4500 0.6931471824645996\n",
      "4600 0.6931471824645996\n",
      "4700 0.6931471824645996\n",
      "4800 0.6931471824645996\n",
      "4900 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "5100 0.6931471824645996\n",
      "5200 0.6931471824645996\n",
      "5300 0.6931471824645996\n",
      "5400 0.6931471824645996\n",
      "5500 0.6931471824645996\n",
      "5600 0.6931471824645996\n",
      "5700 0.6931471824645996\n",
      "5800 0.6931471824645996\n",
      "5900 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "6100 0.6931471824645996\n",
      "6200 0.6931471824645996\n",
      "6300 0.6931471824645996\n",
      "6400 0.6931471824645996\n",
      "6500 0.6931471824645996\n",
      "6600 0.6931471824645996\n",
      "6700 0.6931471824645996\n",
      "6800 0.6931471824645996\n",
      "6900 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "7100 0.6931471824645996\n",
      "7200 0.6931471824645996\n",
      "7300 0.6931471824645996\n",
      "7400 0.6931471824645996\n",
      "7500 0.6931471824645996\n",
      "7600 0.6931471824645996\n",
      "7700 0.6931471824645996\n",
      "7800 0.6931471824645996\n",
      "7900 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "8100 0.6931471824645996\n",
      "8200 0.6931471824645996\n",
      "8300 0.6931471824645996\n",
      "8400 0.6931471824645996\n",
      "8500 0.6931471824645996\n",
      "8600 0.6931471824645996\n",
      "8700 0.6931471824645996\n",
      "8800 0.6931471824645996\n",
      "8900 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "9100 0.6931471824645996\n",
      "9200 0.6931471824645996\n",
      "9300 0.6931471824645996\n",
      "9400 0.6931471824645996\n",
      "9500 0.6931471824645996\n",
      "9600 0.6931471824645996\n",
      "9700 0.6931471824645996\n",
      "9800 0.6931471824645996\n",
      "9900 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "epoch = 10000\n",
    "for step in range(epoch + 1):\n",
    "    #forward\n",
    "    l1 = torch.add(torch.matmul(X,w1),b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1,w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    \n",
    "    #Backpropagation (Chain Rule)\n",
    "    #Loss derivative\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    #weigth update\n",
    "    w1 = w1 - lr * d_w1\n",
    "    b1 = b1 - lr * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - lr * d_w2\n",
    "    b2 = b2 - lr * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7346739768981934\n",
      "100 0.6932229399681091\n",
      "200 0.6931405067443848\n",
      "300 0.6930267810821533\n",
      "400 0.6926414966583252\n",
      "500 0.6901740431785583\n",
      "600 0.6634379625320435\n",
      "700 0.5491836071014404\n",
      "800 0.4039493203163147\n",
      "900 0.15778645873069763\n",
      "1000 0.07213657349348068\n",
      "1100 0.04408682882785797\n",
      "1200 0.0312125775963068\n",
      "1300 0.023987866938114166\n",
      "1400 0.019408047199249268\n",
      "1500 0.016261592507362366\n",
      "1600 0.013973670080304146\n",
      "1700 0.012238546274602413\n",
      "1800 0.010879326611757278\n",
      "1900 0.00978686474263668\n",
      "2000 0.008890369907021523\n",
      "2100 0.008141839876770973\n",
      "2200 0.007507735397666693\n",
      "2300 0.006963868159800768\n",
      "2400 0.006492419168353081\n",
      "2500 0.006079902872443199\n",
      "2600 0.005715972278267145\n",
      "2700 0.005392673425376415\n",
      "2800 0.005103521514683962\n",
      "2900 0.004843408707529306\n",
      "3000 0.004608238115906715\n",
      "3100 0.004394622519612312\n",
      "3200 0.004199673887342215\n",
      "3300 0.004021090921014547\n",
      "3400 0.003856964409351349\n",
      "3500 0.0037055518478155136\n",
      "3600 0.0035654702223837376\n",
      "3700 0.0034354592207819223\n",
      "3800 0.0033144974149763584\n",
      "3900 0.0032017293851822615\n",
      "4000 0.0030962848104536533\n",
      "4100 0.002997488947585225\n",
      "4200 0.0029047715943306684\n",
      "4300 0.002817547880113125\n",
      "4400 0.002735383342951536\n",
      "4500 0.002657813485711813\n",
      "4600 0.002584477886557579\n",
      "4700 0.002515062689781189\n",
      "4800 0.0024492228403687477\n",
      "4900 0.002386748790740967\n",
      "5000 0.002327325753867626\n",
      "5100 0.0022708042524755\n",
      "5200 0.002216900233179331\n",
      "5300 0.002165492856875062\n",
      "5400 0.002116373274475336\n",
      "5500 0.0020694814156740904\n",
      "5600 0.0020245779305696487\n",
      "5700 0.0019815429113805294\n",
      "5800 0.0019402867183089256\n",
      "5900 0.0019006896764039993\n",
      "6000 0.0018627066165208817\n",
      "6100 0.0018261733930557966\n",
      "6200 0.0017910596216097474\n",
      "6300 0.001757260994054377\n",
      "6400 0.0017246876377612352\n",
      "6500 0.001693279598839581\n",
      "6600 0.0016629921738058329\n",
      "6700 0.001633795560337603\n",
      "6800 0.0016055847518146038\n",
      "6900 0.0015783151611685753\n",
      "7000 0.0015519268345087767\n",
      "7100 0.001526404870674014\n",
      "7200 0.001501764403656125\n",
      "7300 0.0014778258046135306\n",
      "7400 0.0014546936145052314\n",
      "7500 0.001432218705303967\n",
      "7600 0.001410460565239191\n",
      "7700 0.0013893446885049343\n",
      "7800 0.001368870958685875\n",
      "7900 0.0013489199336618185\n",
      "8000 0.001329595921561122\n",
      "8100 0.001310824416577816\n",
      "8200 0.001292486093007028\n",
      "8300 0.0012747449800372124\n",
      "8400 0.0012574219144880772\n",
      "8500 0.0012405766174197197\n",
      "8600 0.0012241791700944304\n",
      "8700 0.0012082147877663374\n",
      "8800 0.0011926533188670874\n",
      "8900 0.0011774951126426458\n",
      "9000 0.0011626803316175938\n",
      "9100 0.0011482683476060629\n",
      "9200 0.0011341999052092433\n",
      "9300 0.0011204598704352975\n",
      "9400 0.0011070482432842255\n",
      "9500 0.0010939798085018992\n",
      "9600 0.0010811800602823496\n",
      "9700 0.0010686938185244799\n",
      "9800 0.0010564911644905806\n",
      "9900 0.0010445124935358763\n",
      "10000 0.001032862113788724\n"
     ]
    }
   ],
   "source": [
    "#nn Layers\n",
    "linear1 = torch.nn.Linear(2,2, bias = True)\n",
    "linear2 = torch.nn.Linear(2,1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "epoch = 10000\n",
    "for step in range(epoch + 1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #cos/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7151408195495605\n",
      "100 0.6931414604187012\n",
      "200 0.6931411027908325\n",
      "300 0.6931408643722534\n",
      "400 0.6931405067443848\n",
      "500 0.6931401491165161\n",
      "600 0.693139910697937\n",
      "700 0.6931394934654236\n",
      "800 0.6931390762329102\n",
      "900 0.6931387782096863\n",
      "1000 0.6931383609771729\n",
      "1100 0.6931379437446594\n",
      "1200 0.6931375861167908\n",
      "1300 0.6931371092796326\n",
      "1400 0.6931366920471191\n",
      "1500 0.6931362152099609\n",
      "1600 0.6931357383728027\n",
      "1700 0.693135142326355\n",
      "1800 0.6931346654891968\n",
      "1900 0.693134069442749\n",
      "2000 0.693133533000946\n",
      "2100 0.6931329965591431\n",
      "2200 0.6931322813034058\n",
      "2300 0.693131685256958\n",
      "2400 0.6931308507919312\n",
      "2500 0.6931301355361938\n",
      "2600 0.693129301071167\n",
      "2700 0.6931284666061401\n",
      "2800 0.6931275725364685\n",
      "2900 0.6931266784667969\n",
      "3000 0.6931256055831909\n",
      "3100 0.6931245923042297\n",
      "3200 0.6931234002113342\n",
      "3300 0.6931222081184387\n",
      "3400 0.6931208372116089\n",
      "3500 0.6931194067001343\n",
      "3600 0.6931179165840149\n",
      "3700 0.6931162476539612\n",
      "3800 0.6931144595146179\n",
      "3900 0.6931124925613403\n",
      "4000 0.6931103467941284\n",
      "4100 0.6931080222129822\n",
      "4200 0.6931054592132568\n",
      "4300 0.6931027173995972\n",
      "4400 0.6930995583534241\n",
      "4500 0.6930961608886719\n",
      "4600 0.6930922865867615\n",
      "4700 0.6930879950523376\n",
      "4800 0.6930831670761108\n",
      "4900 0.6930776834487915\n",
      "5000 0.6930714845657349\n",
      "5100 0.6930643320083618\n",
      "5200 0.6930561065673828\n",
      "5300 0.6930464506149292\n",
      "5400 0.6930352449417114\n",
      "5500 0.6930217742919922\n",
      "5600 0.6930056214332581\n",
      "5700 0.6929858922958374\n",
      "5800 0.692961573600769\n",
      "5900 0.6929307579994202\n",
      "6000 0.6928911805152893\n",
      "6100 0.6928387880325317\n",
      "6200 0.692767322063446\n",
      "6300 0.6926659345626831\n",
      "6400 0.6925147771835327\n",
      "6500 0.6922742128372192\n",
      "6600 0.6918560266494751\n",
      "6700 0.691028356552124\n",
      "6800 0.6890244483947754\n",
      "6900 0.6821352243423462\n",
      "7000 0.6403465867042542\n",
      "7100 0.5204160213470459\n",
      "7200 0.05847170948982239\n",
      "7300 0.011402999982237816\n",
      "7400 0.005769500508904457\n",
      "7500 0.0037597387563437223\n",
      "7600 0.002754418645054102\n",
      "7700 0.0021583966445177794\n",
      "7800 0.001766635337844491\n",
      "7900 0.0014907822478562593\n",
      "8000 0.0012866355245932937\n",
      "8100 0.0011298195458948612\n",
      "8200 0.0010057538747787476\n",
      "8300 0.0009053432149812579\n",
      "8400 0.0008224657503888011\n",
      "8500 0.0007529119029641151\n",
      "8600 0.0006938157603144646\n",
      "8700 0.0006430433131754398\n",
      "8800 0.0005988785997033119\n",
      "8900 0.0005602323217317462\n",
      "9000 0.0005260453326627612\n",
      "9100 0.0004956612247042358\n",
      "9200 0.000468483311124146\n",
      "9300 0.0004440193297341466\n",
      "9400 0.0004218963731545955\n",
      "9500 0.0004018013132736087\n",
      "9600 0.00038345076609402895\n",
      "9700 0.00036665084189735353\n",
      "9800 0.0003512076800689101\n",
      "9900 0.0003369423793628812\n",
      "10000 0.0003238100907765329\n"
     ]
    }
   ],
   "source": [
    "#nn Layers\n",
    "linear1 = torch.nn.Linear(2,10, bias = True)\n",
    "linear2 = torch.nn.Linear(10,10, bias = True)\n",
    "linear3 = torch.nn.Linear(10,10, bias = True)\n",
    "linear4 = torch.nn.Linear(10,1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "epoch = 10000\n",
    "for step in range(epoch + 1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #cos/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
